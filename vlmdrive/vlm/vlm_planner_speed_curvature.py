"""
VLMPlannerSpeedCurvature

This module implements a speed-curvature planner that extends VLMPlannerBase.
It computes the ego vehicle's historical speed, curvature, and relative waypoints 
from perception data, and it post-processes the output of a vision-language model 
to produce waypoint predictions.
"""

import re
import json
import numpy as np
import torch

from vlmdrive import VLMDRIVE_REGISTRY
from vlmdrive.vlm.vlm_planner_base import VLMPlannerBase

@VLMDRIVE_REGISTRY.register
class VLMPlannerSpeedCurvature(VLMPlannerBase):
    """
    VLMPlannerSpeedCurvature extends VLMPlannerBase to predict waypoints based on 
    speed and curvature outputs generated by a vision-language model. It processes 
    perception data to build an ego vehicle history and post-processes LLM outputs.
    """
    
    def _result_to_prediction_dict(self, result):
        """
        Convert the predicted speed-curvature pairs into a dictionary with keys
        'target_speed', 'curvature', and 'dt' (time step between predictions).
        
        Args:
            result (torch.Tensor): Tensor of shape (N, 2) containing speed-curvature pairs.
            
        Returns:
            dict: Dictionary with keys 'target_speed', 'curvature', and 'dt'.
        """
        
        predicted_result = {
            'target_speed': result[:, 0],
            'curvature': result[:, 1],
            'dt': 0.5  # Time step between predictions
        }
        return predicted_result

    def _get_ego_history(self, perception_memory_bank, agent_idx):
        """
        Build a JSON string containing the ego vehicle's historical speed, curvature,
        and relative waypoints for each time frame in the perception_memory_bank.

        The current frame's position is used as a reference for computing relative waypoints.

        Args:
            perception_memory_bank (list[dict]): List of perception records.
            agent_idx (int): Index of the ego vehicle in the perception data.

        Returns:
            str: A JSON string with the structure:
                {
                  "ego_history": [
                    {"timestamp": ..., "speed": ..., "curvature": ..., "waypoints": [x, y]},
                    ...
                  ]
                }
        """
        ego_history_list = []
        prev_position = None
        prev_yaw = None
        dt = 0.5  # Time interval in seconds

        # Current pose is used as reference for relative waypoints
        curr_pose = perception_memory_bank[-1]['detmap_pose'][agent_idx].cpu().numpy()
        curr_x, curr_y, _ = float(curr_pose[0]), float(curr_pose[1]), float(curr_pose[2])

        # Process each frame in the history (excluding the current frame)
        for frame_data in perception_memory_bank[:-1]:
            timestamp = frame_data['timestamp']
            # Extract ego pose: [x, y, yaw]
            ego_pose = frame_data['detmap_pose'][agent_idx].cpu().numpy()
            x, y, _ = float(ego_pose[0]), float(
                ego_pose[1]), float(ego_pose[2])
            yaw = frame_data['ego_yaw'][agent_idx]

            # Calculate speed as the derivative of position
            if prev_position is not None:
                dx = x - prev_position[0]
                dy = y - prev_position[1]
                speed = np.sqrt(dx * dx + dy * dy) / dt
            else:
                speed = 0.0

            # Calculate curvature as the change in yaw per unit distance
            if prev_yaw is not None:
                d_yaw = yaw - prev_yaw
                distance = max(1e-6, speed * dt)
                curvature = d_yaw / distance
            else:
                curvature = 0.0

            record = {
                "timestamp": timestamp,
                "speed": round(speed, 5),
                "curvature": round(curvature, 5),
                # Compute relative waypoint with respect to the current frame
                "waypoints": [x - curr_x, y - curr_y]
            }
            ego_history_list.append(record)
            prev_position = (x, y)
            prev_yaw = yaw

        # Wrap the history list into a JSON structure and convert it to a string
        ego_history_json = {"ego_history": ego_history_list}
        return json.dumps(ego_history_json, indent=2)


    def _postprocess_result(self, result):
        """
        Parse the predicted JSON from the LLM output to extract speed-curvature pairs,
        and convert them into a torch.Tensor.

        The expected JSON format must include a key 'predicted_speeds_curvatures' 
        containing a list of [speed, curvature] pairs.

        Args:
            result (str): Raw string output from the LLM.

        Returns:
            torch.Tensor: Tensor of shape (N, 2) where N is the number of predicted pairs.
        """
        # 1) Extract JSON substring from the result using regex
        json_pattern = re.compile(
            r"```json\s*([\s\S]*?)\s*```|\{[\s\S]*\}",
            re.MULTILINE
        )
        json_str = None

        try:
            json_match = json_pattern.search(result)
            if json_match:
                # Use group(1) if available; otherwise, use the entire match
                json_str = json_match.group(1) if json_match.group(1) else json_match.group(0)
            else:
                raise ValueError("No JSON content found in the model output.")
        except Exception as e:
            raise ValueError(f"Failed to locate JSON via regex: {str(e)}")

        # 2) Load the JSON structure
        try:
            json_result = json.loads(json_str)
        except json.JSONDecodeError as e:
            raise ValueError(f"Failed to parse JSON: {e}")

        # 3) Retrieve the speed-curvature pairs from the JSON
        if "predicted_speeds_curvatures" not in json_result:
            raise ValueError(
                "JSON does not contain 'predicted_speeds_curvatures' key.")

        speed_curv_list = json_result["predicted_speeds_curvatures"]
        if not isinstance(speed_curv_list, list):
            raise ValueError("The 'predicted_speeds_curvatures' should be a list of pairs.")
        
        speed_curv = torch.tensor(speed_curv_list, dtype=torch.float32)
        return speed_curv








